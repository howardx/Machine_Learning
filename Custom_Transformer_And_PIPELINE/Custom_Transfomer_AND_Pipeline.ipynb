{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"max_rows\", 10)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "with open(\"data\\\\adult.names\") as fin:\n",
    "    notes = fin.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Transformers\n",
    "\n",
    "- all have .transform() method\n",
    "- OneHotEncoder, PCA, SVD, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Estimators\n",
    "\n",
    "- all have .predict() method\n",
    "- DecisionTreeClassifier(), LogisticRegression(), LinearRegression(), RandomForestClassifier(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dta = pd.read_csv(\"data/adult.data.cleaned.csv.gz\", compression=\"gzip\")\n",
    "test = pd.read_csv(\"data/adult.test.cleaned.csv.gz\", compression=\"gzip\")\n",
    "\n",
    "y = dta.pop(\"income\")\n",
    "y_test = test.pop(\"income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing using LabelBinarizer Transformer\n",
    "- Scikit-learn estimators only take numeric data (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "binarizer = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator.fit_transform() is equivalent of doing\n",
    "estimator.fit(), then \n",
    "estimator.transform()\n",
    "\n",
    "estimator.fit() mutates the estimator object according to given dataset\n",
    "\n",
    "estimator.transform() use the mutated estimator object, apply its ruls to data input and return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no classes_ attribute available\n",
      "['?' 'Cuba' 'India' 'Jamaica' 'United-States']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print binarizer.classes_\n",
    "except:\n",
    "    print \"no classes_ attribute available\"\n",
    "binarizer.fit(dta.native_country.head(15))\n",
    "print binarizer.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United-States', 'United-States', 'United-States', 'United-States',\n",
       "       'Cuba', 'United-States', 'Jamaica', 'United-States',\n",
       "       'United-States', 'United-States', 'United-States', 'India',\n",
       "       'United-States', 'United-States', '?'], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta.native_country.head(15).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform 1-hot encoding\n",
    "binarizer.fit_transform(dta.native_country.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pandas equivalent of LabelBinarizer for doing 1-hot encoding\n",
    "X_train = pd.get_dummies(dta)\n",
    "\n",
    "X_test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'native_country_Holand-Netherlands'], dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "X_train.columns.difference(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a column in testing set for the missing observation, then assign all zeros because of no observation\n",
    "X_test[X_train.columns.difference(X_test.columns)[0]] = 0\n",
    "\n",
    "# make sure that training set and testing set have same column ordering\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of a customized Transformer\n",
    "-  reliably transforms DataFrames and Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass\n",
      "education\n",
      "marital_status\n",
      "occupation\n",
      "relationship\n",
      "race\n",
      "sex\n",
      "native_country\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "\n",
    "class PandasTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, dataframe):\n",
    "        self.columns = dataframe.columns\n",
    "        self.obj_columns = self.get_obj_cols(dataframe, index=True)\n",
    "        obj_index = np.zeros(dataframe.shape[1], dtype=bool)\n",
    "        obj_index[self.obj_columns] = True\n",
    "        self.obj_index = obj_index\n",
    "        \n",
    "    def get_obj_cols(self, dta, index=False):\n",
    "        \"\"\"\n",
    "        Return all column names whose data type is not float\n",
    "        \n",
    "        dta : pd.DataFrame\n",
    "        index : bool\n",
    "                Whether to return column names or the numeric index.\n",
    "                Default False, returns column names.\n",
    "        \"\"\"\n",
    "        columns = dta.columns.tolist()\n",
    "        obj_col_names = list(filter(lambda x : dta[x].dtype.kind == \"O\", \n",
    "                                columns))\n",
    "        if not index:\n",
    "            return obj_col_names\n",
    "        else:\n",
    "            return list(columns.index(col) for col in obj_col_names) \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        # create the binarizer transforms\n",
    "        _transformers = {}\n",
    "        for col in self.obj_columns:\n",
    "            print \"column index:\\n\" + str(col)\n",
    "            print \"column value:\"\n",
    "            print X[:, col]\n",
    "            _transformers.update({col : LabelBinarizer().fit(X[:, col])})\n",
    "        \n",
    "        self._transformers = _transformers\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        \n",
    "        dummies = None\n",
    "        for col in self.obj_columns:\n",
    "            if dummies is None:\n",
    "                dummies = self._transformers[col].transform(X[:, col])\n",
    "            else:\n",
    "                new_dummy = self._transformers[col].transform(X[:, col])\n",
    "                dummies = np.column_stack((dummies, new_dummy))\n",
    "            \n",
    "        # remove original columns\n",
    "        X = X[:, ~self.obj_index]\n",
    "        X = np.column_stack((X, dummies))\n",
    "        return X\n",
    "    \n",
    "    def demo(self):\n",
    "        obj_cols = self.get_obj_cols(dta)\n",
    "\n",
    "        for col in obj_cols:\n",
    "            print col\n",
    "        \n",
    "pt = PandasTransformer(dta)\n",
    "pt.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Decision Tree Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            random_state=0, splitter='best')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state = 0, max_depth = 2)\n",
    "\n",
    "dtree.fit(X_train, y) # does the traning here for decision tree estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Pipeline object,  chained transformers and estimators with same Scikit-learn API\n",
    "- in this case chaining custom PandasTransformer and DecisionTreeClassifier in to a pipeline object, one call does it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "dtree_estimator_pipeline = Pipeline([('transformer', PandasTransformer(dta)), \n",
    "                            ('dtree', dtree)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column index:\n",
      "1\n",
      "column value:\n",
      "['State-gov' 'Self-emp-not-inc' 'Private' ..., 'Private' 'Private'\n",
      " 'Self-emp-inc']\n",
      "column index:\n",
      "3\n",
      "column value:\n",
      "['Bachelors' 'Bachelors' 'HS-grad' ..., 'HS-grad' 'HS-grad' 'HS-grad']\n",
      "column index:\n",
      "5\n",
      "column value:\n",
      "['Never-married' 'Married-civ-spouse' 'Divorced' ..., 'Widowed'\n",
      " 'Never-married' 'Married-civ-spouse']\n",
      "column index:\n",
      "6\n",
      "column value:\n",
      "['Adm-clerical' 'Exec-managerial' 'Handlers-cleaners' ..., 'Adm-clerical'\n",
      " 'Adm-clerical' 'Exec-managerial']\n",
      "column index:\n",
      "7\n",
      "column value:\n",
      "['Not-in-family' 'Husband' 'Not-in-family' ..., 'Unmarried' 'Own-child'\n",
      " 'Wife']\n",
      "column index:\n",
      "8\n",
      "column value:\n",
      "['White' 'White' 'White' ..., 'White' 'White' 'White']\n",
      "column index:\n",
      "9\n",
      "column value:\n",
      "['Male' 'Male' 'Male' ..., 'Female' 'Male' 'Female']\n",
      "column index:\n",
      "13\n",
      "column value:\n",
      "['United-States' 'United-States' 'United-States' ..., 'United-States'\n",
      " 'United-States' 'United-States']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transformer', PandasTransformer(dataframe=None)), ('dtree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            random_state=0, splitter='best'))])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_estimator_pipeline.fit(dta, y) # print outs are from PandasTransformer.fit() calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling PandasTransformer part of pipeline\n",
      "column index:\n",
      "1\n",
      "column value:\n",
      "['State-gov' 'Self-emp-not-inc' 'Private' ..., 'Private' 'Private'\n",
      " 'Self-emp-inc']\n",
      "column index:\n",
      "3\n",
      "column value:\n",
      "['Bachelors' 'Bachelors' 'HS-grad' ..., 'HS-grad' 'HS-grad' 'HS-grad']\n",
      "column index:\n",
      "5\n",
      "column value:\n",
      "['Never-married' 'Married-civ-spouse' 'Divorced' ..., 'Widowed'\n",
      " 'Never-married' 'Married-civ-spouse']\n",
      "column index:\n",
      "6\n",
      "column value:\n",
      "['Adm-clerical' 'Exec-managerial' 'Handlers-cleaners' ..., 'Adm-clerical'\n",
      " 'Adm-clerical' 'Exec-managerial']\n",
      "column index:\n",
      "7\n",
      "column value:\n",
      "['Not-in-family' 'Husband' 'Not-in-family' ..., 'Unmarried' 'Own-child'\n",
      " 'Wife']\n",
      "column index:\n",
      "8\n",
      "column value:\n",
      "['White' 'White' 'White' ..., 'White' 'White' 'White']\n",
      "column index:\n",
      "9\n",
      "column value:\n",
      "['Male' 'Male' 'Male' ..., 'Female' 'Male' 'Female']\n",
      "column index:\n",
      "13\n",
      "column value:\n",
      "['United-States' 'United-States' 'United-States' ..., 'United-States'\n",
      " 'United-States' 'United-States']\n",
      "Calling DecisionTreeClassifier part of pipeline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            random_state=0, splitter='best')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can only execute one of the steps within the pipeline\n",
    "\n",
    "print  \"Calling PandasTransformer part of pipeline\"\n",
    "dtree_estimator_pipeline.named_steps['transformer'].fit(dta)\n",
    "\n",
    "print \"Calling DecisionTreeClassifier part of pipeline\"\n",
    "dtree_estimator_pipeline.named_steps['dtree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.95085099,  0.04914901],\n",
       "       [ 0.66898258,  0.33101742],\n",
       "       [ 0.66898258,  0.33101742],\n",
       "       ..., \n",
       "       [ 0.28082345,  0.71917655],\n",
       "       [ 0.95085099,  0.04914901],\n",
       "       [ 0.28082345,  0.71917655]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directly make predictions using pipeline object\n",
    "dtree_estimator_pipeline.predict_proba(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL objects in Scikit-learn can be serialized and save to disk\n",
    "- picklable\n",
    "- joblib is preferable to using pickle, more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named joblib",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-aac54f87566a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named joblib"
     ]
    }
   ],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods\n",
    "- Boosting\n",
    "    - fits series of models sequentially on modified/weighted data\n",
    "    - Gradient Boosting, Ada Boosting\n",
    "- Bagging\n",
    "    - Bootstrap Aggregating (Bagging), NOT sequential\n",
    "    - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
