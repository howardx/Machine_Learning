{
 "metadata": {
  "name": "",
  "signature": "sha256:4cccf6811e6fa1b8c4833ade61d286257fcf57f7e29c8ea1268a12c6d94cadf7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import xgboost as xgb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Using data from UCI machine learning database - dermatology data\n",
      "https://archive.ics.uci.edu/ml/datasets/Dermatology"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# label need to be 0 to num_class -1\n",
      "# in raw data missing numbers are filled in with \"?\" sign\n",
      "\n",
      "inputOpts = dict(delimiter = \",\",\n",
      "               dtype = float,\n",
      "               missing_values={33 : \"?\"},\n",
      "               filling_values={33 : np.nan})\n",
      "\n",
      "data = np.genfromtxt('/user_home/w_howardx/data/dermatology.data', **inputOpts)\n",
      "\n",
      "sz = data.shape\n",
      "print data\n",
      "print sz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  2.   2.   0. ...,   0.  55.   2.]\n",
        " [  3.   3.   3. ...,   0.   8.   1.]\n",
        " [  2.   1.   2. ...,   3.  26.   3.]\n",
        " ..., \n",
        " [  3.   2.   2. ...,   3.  28.   3.]\n",
        " [  2.   1.   3. ...,   3.  50.   3.]\n",
        " [  3.   2.   2. ...,   0.  35.   1.]]\n",
        "(366, 35)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "familyHistory = data[:,10] # take the 10th column to see if data is aligned\n",
      "print len(familyHistory)\n",
      "print max(familyHistory) # should be 1\n",
      "print min(familyHistory) # should be 0\n",
      "print np.unique(familyHistory) # should be [0, 1] only"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "366\n",
        "1.0\n",
        "0.0\n",
        "[ 0.  1.]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "   -- Complete attribute documentation (column index : feature name) -\n",
      "   \n",
      "      Clinical Attributes: (take values 0, 1, 2, 3, unless otherwise indicated)\n",
      "      0: erythema\n",
      "      1: scaling\n",
      "      2: definite borders\n",
      "      3: itching\n",
      "      4: koebner phenomenon\n",
      "      5: polygonal papules\n",
      "      6: follicular papules\n",
      "      7: oral mucosal involvement\n",
      "      8: knee and elbow involvement\n",
      "      9: scalp involvement\n",
      "     10: family history, (0 or 1)\n",
      "     33: Age (linear)\n",
      "\n",
      "     Histopathological Attributes: (take values 0, 1, 2, 3)\n",
      "     11: melanin incontinence\n",
      "     12: eosinophils in the infiltrate\n",
      "     13: PNL infiltrate\n",
      "     14: fibrosis of the papillary dermis\n",
      "     15: exocytosis\n",
      "     16: acanthosis\n",
      "     17: hyperkeratosis\n",
      "     18: parakeratosis\n",
      "     19: clubbing of the rete ridges\n",
      "     20: elongation of the rete ridges\n",
      "     21: thinning of the suprapapillary epidermis\n",
      "     22: spongiform pustule\n",
      "     23: munro microabcess\n",
      "     24: focal hypergranulosis\n",
      "     25: disappearance of the granular layer\n",
      "     26: vacuolisation and damage of basal layer\n",
      "     27: spongiosis\n",
      "     28: saw-tooth appearance of retes\n",
      "     29: follicular horn plug\n",
      "     30: perifollicular parakeratosis\n",
      "     31: inflammatory monoluclear inflitrate\n",
      "     32: band-like infiltrate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "age = data[:,33] # take the 33rd column to see if data is aligned\n",
      "print len(age)\n",
      "print max(age)\n",
      "print min(age)\n",
      "print np.unique(age)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "366\n",
        "75.0\n",
        "0.0\n",
        "[  0.   7.   8.   9.  10.  12.  13.  15.  16.  17.  18.  19.  20.  21.  22.\n",
        "  23.  24.  25.  26.  27.  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.\n",
        "  38.  39.  40.  41.  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.\n",
        "  53.  55.  56.  57.  58.  60.  61.  62.  63.  64.  65.  67.  68.  70.  75.\n",
        "  nan  nan  nan  nan  nan  nan  nan  nan]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label = data[:,34] # take the 34rd column to observe the class label/predictor's distribution\n",
      "print len(label)\n",
      "print max(label)\n",
      "print min(label)\n",
      "print np.unique(label)\n",
      "\n",
      "data[:,34] = data[:,34] - 1 # xgboost requires predictor to start from 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "366\n",
        "6.0\n",
        "1.0\n",
        "[ 1.  2.  3.  4.  5.  6.]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Class Distribution:\n",
      "       Database:  Dermatology\n",
      "       \n",
      "       Class code:   Class:                  Number of instances:\n",
      "       1             psoriasis\t\t\t    112\n",
      "       2             seboreic dermatitis             61\n",
      "       3             lichen planus                   72\n",
      "       4             pityriasis rosea                49\n",
      "       5             cronic dermatitis               52    \n",
      "       6             pityriasis rubra pilaris        20"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train/test split\n",
      "train = data[:int(sz[0] * 0.7), :]\n",
      "test = data[int(sz[0] * 0.7):, :]\n",
      "\n",
      "train_X = train[:,0:33]\n",
      "train_Y = train[:, 34]\n",
      "\n",
      "test_X = test[:,0:33]\n",
      "test_Y = test[:, 34]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert data to xgboost specific structure - DMatrix\n",
      "xg_train = xgb.DMatrix( train_X, label = train_Y)\n",
      "xg_test = xgb.DMatrix(test_X, label = test_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Before running XGboost, we must set three types of parameters: general parameters, booster parameters and task parameters.\n",
      "\n",
      "- General parameters relates to which booster we are using to do boosting, commonly tree or linear model\n",
      "- Booster parameters depends on which booster you have chosen\n",
      "- (Learning) Task parameters that decides on the learning scenario, for example, regression tasks may use different parameters with ranking tasks.\n",
      "- Command line parameters that relates to behavior of CLI version of xgboost."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# setup parameters for xgboost with a python dictionary\n",
      "param = {}\n",
      "\n",
      "# use softmax multi-class classification\n",
      "param['objective'] = 'multi:softmax' # tells boosted trees to output class only (with max probability) - Learning Task Parameter\n",
      "\n",
      "# param[booster] - default is set to \"gbtree\" - gradient boosted tree\n",
      "\n",
      "# scale weight of positive examples\n",
      "param['eta'] = 0.1 # Parameters for Tree Booster - Booster parameter\n",
      "\n",
      "param['max_depth'] = 6 # Parameters for Tree Booster - Booster parameter\n",
      "\n",
      "param['silent'] = 1 # General parameter\n",
      "\n",
      "param['nthread'] = 4\n",
      "\n",
      "param['num_class'] = 6 # number of classes "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# specify traing/testing set for model training - testing set here used as validation set\n",
      "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
      "\n",
      "num_round = 8\n",
      "\n",
      "# train the model\n",
      "bst = xgb.train(param, xg_train, num_round, watchlist );"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[0]\ttrain-merror:0.011719\ttest-merror:0.172727\n",
        "[1]\ttrain-merror:0.015625\ttest-merror:0.127273\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[2]\ttrain-merror:0.011719\ttest-merror:0.109091\n",
        "[3]\ttrain-merror:0.007812\ttest-merror:0.081818\n",
        "[4]\ttrain-merror:0.007812\ttest-merror:0.090909\n",
        "[5]\ttrain-merror:0.007812\ttest-merror:0.081818\n",
        "[6]\ttrain-merror:0.007812\ttest-merror:0.081818\n",
        "[7]\ttrain-merror:0.007812\ttest-merror:0.081818\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get prediction\n",
      "pred = bst.predict( xg_test );\n",
      "\n",
      "print pred\n",
      "\n",
      "print 'prediction testing error:' \n",
      "print sum( int(pred[i]) != test_Y[i] for i in range(len(test_Y))) / float(len(test_Y)) # fraction of wrong predictions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 3.  1.  3.  3.  3.  1.  4.  1.  1.  4.  5.  5.  5.  1.  3.  1.  0.  0.\n",
        "  0.  0.  0.  1.  1.  3.  3.  1.  0.  0.  1.  1.  1.  2.  2.  2.  2.  0.\n",
        "  0.  0.  0.  4.  4.  4.  4.  4.  2.  2.  2.  3.  0.  0.  3.  3.  3.  0.\n",
        "  0.  0.  2.  2.  2.  2.  2.  0.  0.  0.  0.  3.  3.  0.  0.  3.  2.  2.\n",
        "  1.  0.  0.  3.  3.  4.  4.  0.  0.  4.  4.  2.  0.  4.  4.  5.  5.  3.\n",
        "  1.  5.  5.  5.  0.  0.  0.  4.  4.  0.  0.  0.  0.  1.  1.  3.  3.  2.\n",
        "  2.  0.]\n",
        "prediction testing error:\n",
        "0.0818181818182\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# do the same thing again, but output probabilities\n",
      "param['objective'] = 'multi:softprob' # tells boosted trees to output probabilities for each classes - Learning Task Parameter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# need to train xgboost model again with new parameter dictionary\n",
      "bst = xgb.train(param, xg_train, num_round, watchlist );\n",
      "\n",
      "# get prediction, predict() returns a 1D array, need reshape it to (ndata, nclass)\n",
      "yprob = bst.predict( xg_test ).reshape( test_Y.shape[0], 6 )\n",
      "\n",
      "print yprob[0:10, :] # print the first 10 rows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.09830193  0.10269064  0.09823981  0.50448692  0.09817631  0.09810445]\n",
        " [ 0.12231611  0.38839269  0.12223879  0.12282228  0.12215979  0.12207038]\n",
        " [ 0.10886264  0.11372282  0.10879385  0.45125318  0.10872352  0.10864394]\n",
        " [ 0.11239897  0.11741704  0.11232794  0.43342754  0.11225533  0.11217318]\n",
        " [ 0.11239897  0.11741704  0.11232794  0.43342754  0.11225533  0.11217318]\n",
        " [ 0.16591108  0.1704082   0.16580623  0.16659766  0.16569905  0.16557777]\n",
        " [ 0.24767333  0.24031606  0.06515615  0.06546716  0.31632093  0.06506636]\n",
        " [ 0.27607143  0.28340849  0.05560278  0.05945001  0.26994112  0.05552617]\n",
        " [ 0.21142179  0.30871797  0.06056832  0.06475913  0.29404789  0.06048487]\n",
        " [ 0.07814073  0.28802508  0.07809135  0.09864022  0.37911892  0.07798374]]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[0]\ttrain-merror:0.011719\ttest-merror:0.172727\n",
        "[1]\ttrain-merror:0.015625\ttest-merror:0.127273\n",
        "[2]\ttrain-merror:0.011719\ttest-merror:0.109091\n",
        "[3]\ttrain-merror:0.007812\ttest-merror:0.081818\n",
        "[4]\ttrain-merror:0.007812\ttest-merror:0.090909\n",
        "[5]\ttrain-merror:0.007812\ttest-merror:0.081818\n",
        "[6]\ttrain-merror:0.007812\ttest-merror:0.081818\n",
        "[7]\ttrain-merror:0.007812\ttest-merror:0.081818\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ylabel = np.argmax(yprob, axis=1) # taking max probability's column number as final class assigned\n",
      "\n",
      "# ylabel should be exactly the same as pred - output from - param['objective'] = 'multi:softmax'\n",
      "print sum( int(ylabel[i]) != pred[i] for i in range(len(pred)) ) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}