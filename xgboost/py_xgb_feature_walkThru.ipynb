{
 "metadata": {
  "name": "",
  "signature": "sha256:183f718662f0c434d21f7cd6911d014680889d433b70de0aa45c34486a56aee1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy.sparse\n",
      "import pickle\n",
      "import xgboost as xgb\n",
      "\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load file from text file, also binary buffer generated by xgboost\n",
      "dtrain = xgb.DMatrix('/user_home/w_howardx/data/agaricus.txt.train')\n",
      "dtest = xgb.DMatrix('/user_home/w_howardx/data/agaricus.txt.test')\n",
      "\n",
      "print dtrain.num_col()\n",
      "print dtrain.get_label() # label for class of predictor/target/output\n",
      "print dtrain.feature_names\n",
      "print dtrain.feature_types\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "127\n",
        "[ 1.  0.  0. ...,  0.  0.  0.]\n",
        "None\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# specify parameters via map, definition are same as c++ version\n",
      "param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic' }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# specify validations set to watch performance\n",
      "watchlist  = [(dtest,'eval'), (dtrain,'train')]\n",
      "num_round = 2\n",
      "# train the model\n",
      "bst = xgb.train(param, dtrain, num_round, watchlist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[0]\teval-error:0.042831\ttrain-error:0.046522\n",
        "[1]\teval-error:0.021726\ttrain-error:0.022263\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this is prediction\n",
      "preds = bst.predict(dtest)\n",
      "labels = dtest.get_label()\n",
      "print ('error = %f' % ( sum(1 for i in range(len(preds)) if int(preds[i]>0.5)!=labels[i]) /float(len(preds))) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "error = 0.021726\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bst.save_model('/user_home/w_howardx/model/0001.model')\n",
      "\n",
      "# dump model - weak classifiers built - in this case would be decision tree stumps \n",
      "bst.dump_model('/user_home/w_howardx/model/dump.raw.txt')\n",
      "\n",
      "# dump model with feature map - same as above but with feature names listed out at each decision tree node\n",
      "bst.dump_model('/user_home/w_howardx/model/dump.nice.txt', '/user_home/w_howardx/data/feature_map.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# two weak classifiers/decision stumps - stuff in [] are features used to make the split - will be convert to real feature names if given feature_map.txt\n",
      "\n",
      "# booster[0]:\n",
      "  0:[f29<-1.00136e-05] yes=1,no=2,missing=1\n",
      " \n",
      "  -\t1:[f56<-1.00136e-05] yes=3,no=4,missing=3\n",
      "  - -\t\t3:leaf=1.71218\n",
      "  - -\t\t4:leaf=-1.70044\n",
      " \n",
      "  -\t2:[f109<-1.00136e-05] yes=5,no=6,missing=5\n",
      "  - -\t\t5:leaf=-1.94071\n",
      "  - -\t\t6:leaf=1.85965\n",
      "\n",
      "# booster[1]:\n",
      "  0:[f60<-1.00136e-05] yes=1,no=2,missing=1\n",
      "  \n",
      "  -\t1:[f29<-1.00136e-05] yes=3,no=4,missing=3\n",
      "  - -\t\t3:leaf=0.784718\n",
      "  - -\t\t4:leaf=-0.96853\n",
      "  -\t2:leaf=-6.23624\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# save dmatrix into binary buffer - binary file\n",
      "dtest.save_binary('/user_home/w_howardx/data/dtest.buffer')\n",
      "\n",
      "# save model - binary file\n",
      "bst.save_model('/user_home/w_howardx/model/xgb.model')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# model and data serielized in binary format can be reloaded and reused easily\n",
      "bst2 = xgb.Booster(model_file='/user_home/w_howardx/model/xgb.model')\n",
      "dtest2 = xgb.DMatrix('/user_home/w_howardx/data/dtest.buffer')\n",
      "\n",
      "preds2 = bst2.predict(dtest2)\n",
      "\n",
      "# assert they are the same\n",
      "print np.sum(np.abs(preds2-preds)) == 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# xgboost.dMatrix can be built using numpy.ndarray and scipy.sparse (sparse matrix)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = []\n",
      "row = []; col = []; dat = []\n",
      "i = 0\n",
      "\n",
      "for l in open('/user_home/w_howardx/data/agaricus.txt.train'):\n",
      "    arr = l.split()\n",
      "    labels.append(int(arr[0])) # first column is class label\n",
      "    \n",
      "    for it in arr[1:]:\n",
      "        key, value = it.split(':') \n",
      "        \n",
      "        row.append(i) # row index in sparse matrix, same as row index in input file\n",
      "        col.append(int(key)) # column index in sparse matrix, equal to value on the left side of \":\" sign\n",
      "        dat.append(float(value)) # actual numeric value in sparse matrix, equal to value on the right hand side of \":\" sign\n",
      "        \n",
      "    i += 1\n",
      "    \n",
      "csr = scipy.sparse.csr_matrix((dat, (row,col))) # scipy sparse matrix\n",
      "print csr\n",
      "#1st row in input file - 1 3:1 10:1 11:1 21:1 30:1 34:1 36:1 40:1 41:1 53:1 58:1 65:1 69:1 77:1 86:1 88:1 92:1 95:1 102:1 105:1 117:1 124:1\n",
      "# a good way to sanity check the above sparse matrix\n",
      "\n",
      "ndArr = csr.toarray()\n",
      "print ndArr.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 3)\t1.0\n",
        "  (0, 10)\t1.0\n",
        "  (0, 11)\t1.0\n",
        "  (0, 21)\t1.0\n",
        "  (0, 30)\t1.0\n",
        "  (0, 34)\t1.0\n",
        "  (0, 36)\t1.0\n",
        "  (0, 40)\t1.0\n",
        "  (0, 41)\t1.0\n",
        "  (0, 53)\t1.0\n",
        "  (0, 58)\t1.0\n",
        "  (0, 65)\t1.0\n",
        "  (0, 69)\t1.0\n",
        "  (0, 77)\t1.0\n",
        "  (0, 86)\t1.0\n",
        "  (0, 88)\t1.0\n",
        "  (0, 92)\t1.0\n",
        "  (0, 95)\t1.0\n",
        "  (0, 102)\t1.0\n",
        "  (0, 105)\t1.0\n",
        "  (0, 117)\t1.0\n",
        "  (0, 124)\t1.0\n",
        "  (1, 3)\t1.0\n",
        "  (1, 10)\t1.0\n",
        "  (1, 20)\t1.0\n",
        "  :\t:\n",
        "  (6511, 107)\t1.0\n",
        "  (6511, 115)\t1.0\n",
        "  (6511, 121)\t1.0\n",
        "  (6512, 3)\t1.0\n",
        "  (6512, 10)\t1.0\n",
        "  (6512, 11)\t1.0\n",
        "  (6512, 22)\t1.0\n",
        "  (6512, 29)\t1.0\n",
        "  (6512, 32)\t1.0\n",
        "  (6512, 36)\t1.0\n",
        "  (6512, 39)\t1.0\n",
        "  (6512, 52)\t1.0\n",
        "  (6512, 53)\t1.0\n",
        "  (6512, 61)\t1.0\n",
        "  (6512, 65)\t1.0\n",
        "  (6512, 69)\t1.0\n",
        "  (6512, 74)\t1.0\n",
        "  (6512, 83)\t1.0\n",
        "  (6512, 88)\t1.0\n",
        "  (6512, 91)\t1.0\n",
        "  (6512, 95)\t1.0\n",
        "  (6512, 102)\t1.0\n",
        "  (6512, 110)\t1.0\n",
        "  (6512, 115)\t1.0\n",
        "  (6512, 121)\t1.0\n",
        "(6513, 127)\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate dMatrix from scipy.sparse, as sparse matrix only has features, so need to specify labels\n",
      "dtrain = xgb.DMatrix(csr, label = labels)\n",
      "\n",
      "watchlist  = [(dtest,'eval'), (dtrain,'train')]\n",
      "bst = xgb.train(param, dtrain, num_round, watchlist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[0]\teval-error:0.042831\ttrain-error:0.046522\n",
        "[1]\teval-error:0.021726\ttrain-error:0.022263\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}