{
 "metadata": {
  "name": "",
  "signature": "sha256:3fb6837d3728af4bc0e3864a966a5987b41bcd5dcb70a8329a36554b13bf86b6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn\n",
      "import pandas\n",
      "import numpy\n",
      "import scipy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "SKlearn CountVectorizer() Demo - a SKlearn Transformer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_set = [\"this is a test\", \"another test\", \"yet another test\", \"again test\", \"final test ha ha\"]\n",
      "\n",
      "cv = CountVectorizer()\n",
      "cv.fit(training_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
        "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_set = [\"this is another test for this cv\", \"cv\", \"test\"]\n",
      "\n",
      "bag_of_words_sparse = cv.transform(testing_set)\n",
      "print type(bag_of_words_sparse)\n",
      "print bag_of_words_sparse\n",
      "print bag_of_words_sparse.shape # two columns of index, one column of count\n",
      "\n",
      "bag_of_words_dense = bag_of_words_sparse.toarray()\n",
      "print type(bag_of_words_dense)\n",
      "print bag_of_words_dense"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'scipy.sparse.csr.csr_matrix'>\n",
        "  (0, 1)\t1\n",
        "  (0, 4)\t1\n",
        "  (0, 5)\t1\n",
        "  (0, 6)\t2\n",
        "  (2, 5)\t1\n",
        "(3, 8)\n",
        "<type 'numpy.ndarray'>\n",
        "[[0 1 0 0 1 1 2 0]\n",
        " [0 0 0 0 0 0 0 0]\n",
        " [0 0 0 0 0 1 0 0]]\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the unique words in bag of words - column/feature in matrix\n",
      "\n",
      "# The default configuration tokenizes the string by extracting words of at least 2 letters\n",
      "feature_names = cv.get_feature_names() # notice the word \"a\" is not taken in as a feature \n",
      "print feature_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'again', u'another', u'final', u'ha', u'is', u'test', u'this', u'yet']\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# word \"this\" appeared twice in the first data point in testing_set\n",
      "this_index = feature_names.index(\"this\")\n",
      "\n",
      "print bag_of_words_dense[:, this_index] # the column for \"this\" in bag of words dense matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[2 0 0]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# and the sizes match\n",
      "print len(testing_set)\n",
      "print len(feature_names)\n",
      "print bag_of_words_dense.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\n",
        "8\n",
        "(3, 8)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#N-gram using CountVectorizer()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', min_df=1)\n",
      "\n",
      "bigram_analyzer = bigram_vectorizer.build_analyzer()\n",
      "bigram_analyzer('Bi-grams are cool!') == (['bi', 'grams', 'are', 'cool', 'bi grams', 'grams are', 'are cool'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tweak \"ngram_range\" parameter to pick n-grams' n \n",
      "trigram_vectorizer = CountVectorizer(ngram_range=(3, 3), min_df=1)\n",
      "\n",
      "trigram_analyzer = trigram_vectorizer.build_analyzer()\n",
      "trigram_analyzer('Tri-grams are cool also!') "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[u'tri grams are', u'grams are cool', u'are cool also']"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_vectorizer.fit(['Bi-grams are cool!'])\n",
      "bigram_vectorizer.get_feature_names()\n",
      "\n",
      "# analyze() is like a trial step for fit() - can observe the fit result/dictionary by using analyze()\n",
      "print len(bigram_vectorizer.get_feature_names())\n",
      "print len(bigram_analyzer('Bi-grams are cool!'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7\n",
        "7\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "SKlearn TfidfTransformer() demo - a SKlearn Transformer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "transformer = TfidfTransformer()\n",
      "transformer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "TfidfTransformer(norm=u'l2', smooth_idf=True, sublinear_tf=False,\n",
        "         use_idf=True)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf_sparse = transformer.fit_transform(bag_of_words_dense) # can use sparse matrix here also, then will return sparse matrix\n",
      "tfidf_dense = tfidf_sparse.toarray()\n",
      "\n",
      "print bag_of_words_dense\n",
      "print tfidf_dense"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 1 0 0 1 1 2 0]\n",
        " [0 0 0 0 0 0 0 0]\n",
        " [0 0 0 0 0 1 0 0]]\n",
        "[[ 0.          0.38988801  0.          0.          0.38988801  0.29651988\n",
        "   0.77977602  0.        ]\n",
        " [ 0.          0.          0.          0.          0.          0.          0.\n",
        "   0.        ]\n",
        " [ 0.          0.          0.          0.          0.          1.          0.\n",
        "   0.        ]]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "SKlearn TfidfVectorizer() - combination of CountVectorizer() and TfidfTransformer()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [\n",
      "'This is the first document.',\n",
      "'This is the second second document.',\n",
      "'And the third one.',\n",
      "'Is this the first document?',\n",
      "]\n",
      "\n",
      "input_data = [\n",
      "'This is the first test.',\n",
      "'This is another test.',\n",
      "'the third one.',\n",
      "'Is this the first document?',\n",
      "]\n",
      "\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "\n",
      "tfidfV = TfidfVectorizer(min_df=1)\n",
      "tfidfV.fit(corpus) \n",
      "\n",
      "tfidfV_result = tfidfV.transform(input_data) # tfidf result from TfidfVectorizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "countV = CountVectorizer()\n",
      "countV.fit(corpus)\n",
      "\n",
      "bow_corpus_sparse = countV.transform(corpus)\n",
      "bow_input_sparse = countV.transform(input_data)\n",
      "\n",
      "tfidfT = TfidfTransformer()\n",
      "tfidfT.fit(bow_corpus_sparse)\n",
      "\n",
      "tfidfT_result = tfidfT.transform(bow_input_sparse) # tfidf result from CountVectorizer() and TfidfTransformer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# these two should match\n",
      "print tfidfV_result.toarray()\n",
      "print \"\\n\"\n",
      "print tfidfT_result.toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.          0.          0.60313701  0.48829139  0.          0.\n",
        "   0.39921021  0.          0.48829139]\n",
        " [ 0.          0.          0.          0.70710678  0.          0.          0.\n",
        "   0.          0.70710678]\n",
        " [ 0.          0.          0.          0.          0.66338461  0.\n",
        "   0.34618161  0.66338461  0.        ]\n",
        " [ 0.          0.43877674  0.54197657  0.43877674  0.          0.\n",
        "   0.35872874  0.          0.43877674]]\n",
        "\n",
        "\n",
        "[[ 0.          0.          0.60313701  0.48829139  0.          0.\n",
        "   0.39921021  0.          0.48829139]\n",
        " [ 0.          0.          0.          0.70710678  0.          0.          0.\n",
        "   0.          0.70710678]\n",
        " [ 0.          0.          0.          0.          0.66338461  0.\n",
        "   0.34618161  0.66338461  0.        ]\n",
        " [ 0.          0.43877674  0.54197657  0.43877674  0.          0.\n",
        "   0.35872874  0.          0.43877674]]\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Achieve the same result by using Pipeline()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "ppl = Pipeline([\n",
      "  ('bag_of_words', CountVectorizer()),\n",
      "  ('tf_idf', TfidfTransformer())\n",
      "])\n",
      "\n",
      "ppl.fit(corpus)\n",
      "print ppl.transform(input_data).toarray() # tfidf result from Pipeline()\n",
      "\n",
      "print ppl.named_steps['bag_of_words'].get_feature_names()\n",
      "print countV.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.          0.          0.60313701  0.48829139  0.          0.\n",
        "   0.39921021  0.          0.48829139]\n",
        " [ 0.          0.          0.          0.70710678  0.          0.          0.\n",
        "   0.          0.70710678]\n",
        " [ 0.          0.          0.          0.          0.66338461  0.\n",
        "   0.34618161  0.66338461  0.        ]\n",
        " [ 0.          0.43877674  0.54197657  0.43877674  0.          0.\n",
        "   0.35872874  0.          0.43877674]]\n",
        "[u'and', u'document', u'first', u'is', u'one', u'second', u'the', u'third', u'this']\n",
        "[u'and', u'document', u'first', u'is', u'one', u'second', u'the', u'third', u'this']\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}